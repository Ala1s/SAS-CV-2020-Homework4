{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 4 - Image Captioning\n",
    "<br>\n",
    "\n",
    "Задание выполнил(а): *(впишите свои фамилию и имя)*\n",
    "<br>\n",
    "\n",
    "**Дедлайн:** 21.12.2020 23:59\n",
    "\n",
    "\n",
    "### О задании\n",
    "В этом домашнем задании вы узнаете как построить модель для решения задачи Image Captioning с помощью SAS.\n",
    "<br>\n",
    "\n",
    "**Задание построено следующим образом:**\n",
    "- Задание 1: Загрузка данных в CAS (2 балл)\n",
    "- Задание 2: Подготовка обучающих данных (3 балла)\n",
    "- Задание 3: Создание и обучение модели (5 балла)\n",
    "- Задание 4: Проверка качества модели (5 балл)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import swat as sw\n",
    "from swat import *\n",
    "\n",
    "from dlpy import *\n",
    "from dlpy.images import ImageTable\n",
    "from dlpy.applications import *\n",
    "from dlpy.image_captioning import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подключение к серверу CAS**<br>\n",
    "Подключитесь к серверу CAS под своим логином и паролем.<br>\n",
    "Загрузите следующие Action Sets: 'image' и 'deepLearn'.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CAS_CLIENT_SSL_CA_LIST'] = r\"/tmp/4fix/trustedcerts.pem\"\n",
    "\n",
    "# Создаем новую сессию CAS:\n",
    "\n",
    "# Ваш код здесь\n",
    "\n",
    "# Загружаем action sets:\n",
    "\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1: Загрузка данных в CAS**<br>\n",
    "a) Загрузите изображения в ImageTable. Измените размер изображений на 224х224. Выведите примеры изображений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_table = ImageTable.load_files(s,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Измените размер изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведите примеры изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "б) Загрузите подписи к изображениям с помощью функции create_captions_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_path = # Путь к файлу с описаниями изображений\n",
    "delimiter = '\\t'\n",
    "captions = create_captions_table(s,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в) Загрузите веса модели VGG16 (содержатся в архиве с данными) с помощью соответствующего класса в dlpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_pretrain_file = # Путь к файлу с весами модели VGG16 (прилагается к архиву с обучающими данными)\n",
    "\n",
    "features_model = VGG16(s,\n",
    "                       model_table='VGG16',\n",
    "                       \n",
    "                       # Use BGR channel means from training\n",
    "                       # as BGR offset channel values\n",
    "                       offsets=image_table.channel_means,\n",
    "                       \n",
    "                       # Use pretrained .h5 weights file\n",
    "                       pre_trained_weights=True,\n",
    "                       \n",
    "                       # Path to weights file is stored in VGG_pretrain_file\n",
    "                       pre_trained_weights_file=VGG_pretrain_file,\n",
    "                       include_top=True,\n",
    "                       #...\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2: Подготовка обучающих данных**<br>\n",
    "a) Воспользуейтесь функцией get_image_features, чтобы получить фичи для картинок из обучающей выборки с помощью модели VGG16. В качестве целевой перемененной здесь указана переменная '\\_filename\\_0', содержащяя названия файлов с картинками - это сделано для того, чтобы таблицу с полученными фичами можно было обьеденить с таблицей с подписями используя '\\_filename\\_0' как id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit\n",
    "\n",
    "dense_layer = 'fc7'\n",
    "target_var = '_filename_0'\n",
    "\n",
    "features = get_image_features(s, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "б) С помощью action dlJoin обьедините таблицу с полученными фичами с таблицей с подписями используя '\\_filename\\_0' как id. Ссылку на полученную таблицу запишите в переменную captions_features (см. https://bit.ly/3pS26TW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.dljoin("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_features = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в) В исходных данных для каждой картинки дается не один вариант описания (подписи), а сразу 5 различных вариантов. <br>\n",
    "\n",
    "Каждый из вариантов лежит в отдельном столбце. Для того чтобы обучать модель нам нужно, чтобы все подписи к изображениям лежали в одном столбце - таким образом, на каждом шаге мы будем сравнивать результат модели с одним \"верным вариантом\". Соответственно нам нужно преобразовать исходную таблицу так, чтобы из 1 строки в исходной таблице получалось 5 строк в результирующей таблице - каждая с одним из пяти вариантов \"верного ответа\". В исходных данных для каждой картинки дается не один вариант описания (подписи), а сразу 5 различных вариантов. <br>\n",
    "\n",
    "Помочь нам провести такое преобразование может функция reshape_caption_columns. Изучите документацию к ней и преобразуйте с ее помощью таблицу с данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_input = reshape_caption_columns(s,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполните код ниже - он формирует список входных переменных, очевидно, исключая из входных данных колонку с  именами файлов картинок и колонку с предопределенными в исходных данных описаниями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(rnn_input.columns)\n",
    "columns.remove('caption')\n",
    "columns.remove('_filename_0')\n",
    "input_vars = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "г) Конечно же, модель не сможет работать напрямую с текстовыми описаниями картинок, и для того чтобы ее обучать и использовать, нам потребуется предоставить ей какой-то способ переводить текст в вектор чисел и обратно. Для этого чаще всего используются эмбединнги (векторные представления) слов. Для их обучения требуется много времени и данных, так что мы будем использовать уже обученные эмбединнги - файл с векторными представлениями слов размерностью в 100 измерений уже содержится в архиве данных с домашней работой. Его лишь требуется привести в формат, подходящий для SAS. Дополните код ниже и запустите его, чтобы сделать это."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_embedding_file = # Путь к файлу с эмбеддингами\n",
    "\n",
    "raw_embedding_dimension = 100\n",
    "\n",
    "# Use variable 'col_names' to accumulate the \n",
    "# generated header strings for all table columns.\n",
    "col_names = ['term'] + ['_'+str(ii)+'_' for ii in range(1,raw_embedding_dimension+1)]\n",
    "\n",
    "# Pandas reads in the tab-delimited embedding values\n",
    "# from the word vector file with no header\n",
    "df = pd.read_csv(raw_embedding_file, \n",
    "                 names=col_names,\n",
    "                 sep=\" \", \n",
    "                 index_col=0, \n",
    "                 header=None,\n",
    "                 quoting=csv.QUOTE_NONE)\n",
    "df.drop(index=df.head(1).index, inplace=True)\n",
    "\n",
    "# Clean up and omit rows in the table that have \n",
    "# reserved or forbidden index character strings.\n",
    "tmp = [str(df.index[ii]) for ii in range(df.shape[0])]\n",
    "idx = [ii for ii,txt in enumerate(tmp) if ('\"' not in txt) and (\"'\" not in txt)]\n",
    "df1 = df.iloc[idx]\n",
    "\n",
    "pretrained_embedding_file = # Путь к новому файлу, где мы сохраним отформатированные эмбеддинги\n",
    "\n",
    "df1.to_csv(pretrained_embedding_file, \n",
    "           sep='\\t', \n",
    "           header=True,\n",
    "           float_format='%5.6f',\n",
    "           index=True,\n",
    "           quoting=csv.QUOTE_NONE)\n",
    "word_embeddings = pretrained_embedding_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.read_csv(pretrained_embedding_file, skipinitialspace=True, index_col=False, delimiter='\\t')\n",
    "s.upload_frame(embeddings, casout=dict(name='word_embeddings', replace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3: Создание и обучение модели**<br>\n",
    "а) В dlpy для моделирования в задаче image captioning применяется отдельный класс под названием ImageCaptioning. Изучите его параметры и создайте с помощью него модель, содержащую 3 блока и 50 нейронов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captioning_model = ImageCaptioning(s,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "б) Настройте отмеченные ниже параметры обучения и обучите модель. Loss должен опустится ниже 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captioning_model.fit(rnn_input,\n",
    "                     inputs=input_vars,\n",
    "                     data_specs=[dict(type='numericnominal',\n",
    "                                      layer='input',\n",
    "                                      data=input_vars,\n",
    "                                      numericNominalParms=dict(tokensize=100)\n",
    "                                     ),\n",
    "                                 dict(type='text',\n",
    "                                      layer='output',\n",
    "                                    data='caption'\n",
    "                                     )\n",
    "                                ],\n",
    "                     # Save best model weights\n",
    "                     save_best_weights=True,\n",
    "                     \n",
    "                     # Word embeddings files\n",
    "                     text_parms = TextParms(\n",
    "                         init_input_embeddings='word_embeddings',\n",
    "                                            model_output_embeddings=dict(name='word_embeddings_out',\n",
    "                                                                         replace=True\n",
    "                                                                        )\n",
    "                                           ),\n",
    "                     # Random seed key\n",
    "                     seed=12345,\n",
    "                     \n",
    "                     # Use ADAM optimizer\n",
    "                     optimizer=Optimizer(algorithm=dict(method='ADAM',\n",
    "                                                        learningRate= # Настройте это параметр\n",
    "                                                       ),\n",
    "                                         # Optimization parameters\n",
    "                                         mini_batch_size= ,# Настройте это параметр\n",
    "                                         log_level=2,\n",
    "                                         max_epochs=# Настройте это параметр                                         \n",
    "                                        ),\n",
    "                     n_threads=5,\n",
    "                     train_from_scratch=True\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4: Проверка качества модели**<br>\n",
    "а) Проскорьте полученную модель на обучающей выборке с помощью метода predict. Убедитесь, что вы используете сохраненные веса лучшей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captioning_model.predict(# Дополните код,\n",
    "    \n",
    "                         text_parms=dict(initOutputEmbeddings='word_embeddings_out',\n",
    "                                         hasOutputTermIds=True,\n",
    "                                         initInputEmbeddings='word_embeddings',\n",
    "                                         hasInputTermIds=False,\n",
    "                                         embeddingTrainable=False\n",
    "                                        )\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "б) Код ниже записывает результаты скоринга в таблицу results и выводит несколько примеров строк из проскоренной таблицы. От вас требуется написать функцию, которая будет выводить n случайных изображений из обучающей выборки, описание из исходных данных и описание, сформированное моделью, для каждой из картинок. Можете использовать **разумное** количество вложенных/дополнительных функций, если у вас есть такая потребность. Не забудьте продемострировать работу функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = captioning_model.valid_res_tbl\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Напишите код функции здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Продемонстрируйте работу функции здесь"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
